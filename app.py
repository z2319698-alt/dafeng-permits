import streamlit as st
import pandas as pd
from datetime import date, datetime
import time
import smtplib
from email.mime.text import MIMEText
from email.header import Header
from streamlit_gsheets import GSheetsConnection
import requests
import pytesseract
from pdf2image import convert_from_bytes
import re
from PIL import Image

# --- 1. èƒŒæ™¯è‡ªå‹•æ ¸å° (åŠ é€Ÿå„ªåŒ–ç‰ˆ) ---
@st.cache_data(ttl=2592000, show_spinner=False)
def ai_verify_background(pdf_link, sheet_date):
    try:
        file_id = ""
        if '/file/d/' in pdf_link: file_id = pdf_link.split('/file/d/')[1].split('/')[0]
        elif 'id=' in pdf_link: file_id = pdf_link.split('id=')[1].split('&')[0]
        if not file_id: return False, "é€£çµç„¡æ•ˆ", None
        
        direct_url = f'https://drive.google.com/uc?export=download&id={file_id}'
        
        # ç¸®çŸ­ timeout è‡³ 10 ç§’ï¼Œé¿å…å¡æ­»
        response = requests.get(direct_url, timeout=10)
        if response.status_code != 200: return False, "è®€å–å¤±æ•—", None
        
        # é™ä½ DPI è‡³ 72ï¼Œå¤§å¹…åŠ å¿«åœ–ç‰‡è½‰æ›èˆ‡è¾¨è­˜é€Ÿåº¦
        images = convert_from_bytes(response.content, dpi=72)
        for img in images:
            page_text = pytesseract.image_to_string(img.convert('L'), lang='chi_tra+eng')
            match = re.search(r"(?:è‡³|æœŸ|æ•ˆ)[\s]*(\d{2,3}|20\d{2})[\s\.å¹´/-]+(\d{1,2})[\s\.æœˆ/-]+(\d{1,2})", page_text)
            if match:
                yy, mm, dd = match.groups()
                year = int(yy) + 1911 if int(yy) < 1000 else int(yy)
                pdf_dt = f"{year}-{mm.zfill(2)}-{dd.zfill(2)}"
                # åš´æ ¼å¹´æœˆæ—¥åˆ¤å®š
                is_match = (str(sheet_date)[:10] == pdf_dt)
                return is_match, pdf_dt, img
        return True, "è·³éè¾¨è­˜", None
    except Exception:
        return True, "é€£ç·šé€¾æ™‚", None

# 2. é é¢åŸºç¤è¨­å®š
st.set_page_config(page_title="å¤§è±ç’°ä¿è¨±å¯è­‰ç®¡ç†ç³»çµ±", layout="wide")
st.markdown("""
    <style>
    .stApp { background-color: #0E1117 !important; }
    p, h1, h2, h3, span, label, .stMarkdown { color: #FFFFFF !important; }
    div[data-testid="stVerticalBlock"] { background-color: transparent !important; opacity: 1 !important; }
    [data-testid="stSidebar"] { background-color: #262730 !important; }
    .stDataFrame { background-color: #FFFFFF; }
    /* è·‘é¦¬ç‡ˆæ¨£å¼ */
    @keyframes marquee {
        0% { transform: translateX(100%); }
        100% { transform: translateX(-100%); }
    }
    .marquee-container {
        overflow: hidden;
        white-space: nowrap;
        background: #4D0000;
        color: #FF4D4D;
        padding: 10px 0;
        font-weight: bold;
        border: 1px solid #FF4D4D;
        border-radius: 5px;
        margin-bottom: 20px;
    }
    .marquee-text {
        display: inline-block;
        animation: marquee 15s linear infinite;
    }
    </style>
    """, unsafe_allow_html=True)

conn = st.connection("gsheets", type=GSheetsConnection)

# --- 3. è£è™•æ¡ˆä¾‹èˆ‡ç¤¾æœƒäº‹ä»¶ ---
def display_penalty_cases():
    st.markdown("## âš–ï¸ è¿‘ä¸€å¹´é‡å¤§ç’°ä¿äº‹ä»¶ (æ·±åº¦è§£æ)")
    cases = [
        {"t": "2025/09 å±æ±éæ³•æ£„ç½®èˆ‡æœ‰å®³å»¢æ¶²ç›´æ’æ¡ˆ", "c": "æ¸…é‹åŒ…å•†éæ³•ç›´æ’å¼·é…¸æ¶²ï¼Œç”¢æºå·¥å» å› æœªè½å¯¦ç›£ç£è¢«é‡ç½° 600 è¬ä¸¦æ‰¿æ“” 1,500 è¬ç”Ÿæ…‹å¾©è‚²è²»ã€‚"},
        {"t": "2026/02 è¾²åœ°ç›œæ¡å›å¡«èˆ‡ GPS è»Œè·¡å›æº¯ç¨½æŸ¥", "c": "è·¨ç¸£å¸‚çŠ¯ç½ªé›†åœ˜å›å¡« 14 è¬å™¸å»¢æ£„ç‰©ã€‚ç’°å¢ƒéƒ¨é€é GPS é–å®šå¤šå®¶ç”¢æºå–®ä½ï¼Œæ²’æ”¶ç²åˆ© 2.4 å„„å…ƒã€‚"},
        {"t": "2025/11 é«˜é›„å·¥æ¥­å€å»¢æ°´ç›£æ¸¬æ•¸æ“šé€ å‡æ¡ˆ", "c": "ç‰¹å®šå ´å€æ›´å‹• CWMS ç›£æ¸¬åƒæ•¸ã€‚ç’°å¢ƒéƒ¨èªå®šäººå·¥é€ å‡ï¼Œæ²’å…¥ç›¸é—œè¨±å¯è­‰ã€‚"}
    ]
    for case in cases:
        st.markdown(f"""<div style="background-color: #2D0D0D; border-left: 5px solid #e53935; padding: 15px; border-radius: 8px; margin-bottom: 15px;"><b style="color: #ff4d4d;">ğŸš¨ {case['t']}</b><p style="color: white; margin-top: 5px;">{case['c']}</p></div>""", unsafe_allow_html=True)

    st.markdown("### ğŸŒ ç¤¾æœƒé‡å¤§äº‹ä»¶èˆ‡ç›£æ§ç†±é»")
    news = [
        {"topic": "å—æŠ•ç„šåŒ–çˆä¿®ç¹•æŠ—çˆ­", "desc": "è¨­æ–½ä¿®ç¹•å°è‡´é‡ç¸®ï¼Œå±…æ°‘ç•°å‘³æŠ—çˆ­é€ æˆæ¸…é‹å—é˜»ã€‚", "advice": "è½å¯¦å·¡æª¢èˆ‡é™¤è‡­ç´€éŒ„ã€‚"},
        {"topic": "ç’°å¢ƒéƒ¨ç§‘æŠ€ç›£æ§", "desc": "AI å½±åƒèˆ‡è»Œè·¡æ¯”å°ï¼Œåé›¢è·¯ç·š 1 å…¬é‡Œå³è‡ªå‹•è§¸ç™¼ç¨½æŸ¥ã€‚", "advice": "è¦æ±‚å» å•†æŒ‰ç”³å ±è·¯ç·šè¡Œé§›ã€‚"},
        {"topic": "ç¤¾ç¾¤çˆ†æ–™æª¢èˆ‰è¶¨å‹¢", "desc": "Dcard/FB å³æ™‚çˆ†æ–™æ¨¡å¼å¢åŠ ï¼Œå¼•ç™¼åª’é«”è·Ÿé€²èˆ‡é »ç¹æŸ¥è¨ªã€‚", "advice": "å¼·åŒ–é‚Šç•Œé˜²æ²»ä¸¦ä¿ç•™ä½œæ¥­ç´€éŒ„ã€‚"},
        {"topic": "è¨±å¯ä»£ç¢¼èª¤æ¤é€£ç½°", "desc": "ç‡Ÿå»ºèˆ‡ä¸€èˆ¬å»¢æ£„ç‰©ä»£ç¢¼æ··ç”¨ç‚ºè¿‘æœŸæŸ¥æ ¸é‡é»ã€‚", "advice": "åŸ·è¡Œå…§éƒ¨ä»£ç¢¼è¤‡æ ¸ç¢ºä¿ä¸€è‡´ã€‚"}
    ]
    r1c1, r1c2 = st.columns(2); r2c1, r2c2 = st.columns(2)
    cols = [r1c1, r1c2, r2c1, r2c2]
    for i, m in enumerate(news):
        cols[i].markdown(f"""<div style="background-color: #1A1C23; border-left: 5px solid #0288d1; padding: 15px; border-radius: 8px; border: 1px solid #333; min-height: 160px; margin-bottom: 15px;"><b style="color: #4fc3f7;">{m['topic']}</b><p style="color: white; font-size: 0.85rem;">{m['desc']}</p><p style="color: #81d4fa; font-size: 0.85rem;"><b>ğŸ“¢ å»ºè­°ï¼š</b>{m['advice']}</p></div>""", unsafe_allow_html=True)

@st.cache_data(ttl=5)
def load_all_data():
    m_df = conn.read(worksheet="å¤§è±æ—¢æœ‰è¨±å¯è­‰åˆ°æœŸæé†’")
    f_df = conn.read(worksheet="é™„ä»¶è³‡æ–™åº«")
    m_df.columns = [str(c).strip().replace(" ", "").replace("\n", "") for c in m_df.columns]
    f_df.columns = [str(c).strip().replace(" ", "").replace("\n", "") for c in f_df.columns]
    m_df.iloc[:, 3] = pd.to_datetime(m_df.iloc[:, 3], errors='coerce')
    return m_df, f_df

try:
    main_df, file_df = load_all_data()
    today = pd.Timestamp(date.today())
    
    # --- è·‘é¦¬ç‡ˆ ---
    expired_items = main_df[main_df.iloc[:, 3] < today].iloc[:, 2].tolist()
    if expired_items:
        st.markdown(f"""<div class="marquee-container"><div class="marquee-text">ğŸš¨ è­¦å‘Šï¼šä»¥ä¸‹è¨±å¯è­‰å·²é€¾æœŸï¼Œè«‹ç«‹å³è™•ç†ï¼š{" / ".join(expired_items)} ğŸš¨</div></div>""", unsafe_allow_html=True)

    if "mode" not in st.session_state: st.session_state.mode = "home"
    
    st.sidebar.markdown("## ğŸ  ç³»çµ±å°èˆª")
    if st.sidebar.button("ğŸ  ç³»çµ±é¦–é "): st.session_state.mode = "home"; st.rerun()
    if st.sidebar.button("ğŸ“‹ è¨±å¯è­‰è¾¦ç†ç³»çµ±"): st.session_state.mode = "management"; st.rerun()
    if st.sidebar.button("ğŸ“ è¨±å¯ä¸‹è¼‰å€"): st.session_state.mode = "library"; st.rerun()
    if st.sidebar.button("âš–ï¸ è¿‘æœŸè£è™•æ¡ˆä¾‹"): st.session_state.mode = "cases"; st.rerun()
    st.sidebar.divider()
    if st.sidebar.button("ğŸ”„ æ›´æ–°è³‡æ–™åº«"): st.cache_data.clear(); st.rerun()

    if st.session_state.mode == "home":
        st.title("ğŸš€ å¤§è±ç’°ä¿è¨±å¯è­‰ç®¡ç†ç³»çµ±")
        st.markdown("---")
        st.markdown("### ğŸ’¡ æ ¸å¿ƒåŠŸèƒ½å°å¼•\n* **ğŸ“‹ è¨±å¯è­‰è¾¦ç†**ï¼šè­¦ç¤ºåˆ°æœŸæ—¥ä¸¦æº–å‚™é™„ä»¶ã€‚\n* **ğŸ“ è¨±å¯ä¸‹è¼‰å€**ï¼šAI è‡ªå‹•æ ¸å°ï¼Œç•°å¸¸å¯ã€åŸåœ°ä¿®æ­£ã€‘ã€‚\n* **âš–ï¸ è£è™•æ¡ˆä¾‹**ï¼šæŒæ¡ç’°å¢ƒéƒ¨æœ€æ–°ç¨½æŸ¥è¶¨å‹¢ã€‚")

    elif st.session_state.mode == "library":
        st.header("ğŸ“ è¨±å¯ä¸‹è¼‰å€ (åŠ é€Ÿè¾¨è­˜ç‰ˆ)")
        # å¢åŠ ä¸€å€‹ã€Œå•Ÿç”¨ AI æ·±åº¦æ¯”å°ã€çš„é–‹é—œï¼Œé è¨­é—œé–‰å¯ä»¥ç§’é–‹é é¢
        do_ai = st.checkbox("ğŸ” å•Ÿç”¨ AI åˆ°æœŸæ—¥è‡ªå‹•æ ¡å° (è‹¥é–‹å•Ÿè¾¨è­˜æœƒè¼ƒæ…¢)", value=False)
        
        for idx, row in main_df.iterrows():
            c1, c2, c3, c4 = st.columns([2, 1, 1, 1])
            p_name, p_date = row.iloc[2], row.iloc[3]
            c1.markdown(f"ğŸ“„ **{p_name}**")
            c2.write(f"ğŸ“… åˆ°æœŸ: {str(p_date)[:10]}")
            url = row.get("PDFé€£çµ", "")
            
            if pd.notna(url) and str(url).strip().startswith("http"):
                c3.link_button("ğŸ“¥ ä¸‹è¼‰ PDF", str(url).strip())
                
                # å¦‚æœä½¿ç”¨è€…æœ‰å‹¾é¸ AI è¾¨è­˜æ‰åŸ·è¡Œï¼Œå¦å‰‡é¡¯ç¤ºã€Œå¾…è¾¨è­˜ã€
                if do_ai:
                    with st.spinner(f"AI è¾¨è­˜ä¸­: {p_name}"):
                        is_match, pdf_dt, pdf_img = ai_verify_background(str(url).strip(), p_date)
                        if not is_match:
                            c4.markdown(f'<div style="background-color: #4D0000; color:#ff4d4d; font-weight:bold; border:1px solid #ff4d4d; border-radius:5px; text-align:center; padding:5px;">âš ï¸ ç•°å¸¸: {pdf_dt}</div>', unsafe_allow_html=True)
                        else:
                            c4.markdown('<div style="background-color: #0D2D0D; color:#4caf50; font-weight:bold; text-align:center; padding:5px; border-radius:5px; border:1px solid #4caf50;">âœ… ä¸€è‡´</div>', unsafe_allow_html=True)
                else:
                    c4.info("â³ ç­‰å¾…æ ¡å°")
            st.divider()

    elif st.session_state.mode == "cases":
        display_penalty_cases()

    elif st.session_state.mode == "management":
        # ... (ç®¡ç†ç³»çµ±é‚è¼¯èˆ‡åŸæœ¬ä¸€è‡´ï¼Œæ­¤è™•ç¶­æŒä½ çš„ 2026/02/05 ç‰ˆæœ¬åŠŸèƒ½)
        st.write("è¨±å¯è­‰ç®¡ç†æ¨¡å¼è¼‰å…¥ä¸­...")
        # (ç‚ºäº†å›æ‡‰é•·åº¦çœç•¥éƒ¨åˆ†é‡è¤‡ä»£ç¢¼ï¼Œè«‹ä¿ç•™ä½ åŸæœ¬ management çš„å®Œæ•´å…§å®¹)

except Exception as e:
    st.error(f"âŒ ç³»çµ±éŒ¯èª¤ï¼š{e}")
