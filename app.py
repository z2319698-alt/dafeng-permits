import streamlit as st
import pandas as pd
from datetime import date, datetime
import time
from streamlit_gsheets import GSheetsConnection
import requests
import pytesseract
from pdf2image import convert_from_bytes
import re

# --- 1. èƒŒæ™¯è‡ªå‹•æ ¸å°é‚è¼¯ (å¿«å–é‡‘é‘°åŠ å…¥æœˆä»½ï¼Œé”æˆæ¯æœˆè‡ªå‹•æ›´æ–°ä¸€æ¬¡) ---
@st.cache_data(ttl=2592000)
def ai_verify_background(pdf_link, sheet_date):
    # å¿«å–é‡‘é‘°æœƒè·Ÿéš¨ pdf_link èˆ‡ç•¶å‰æœˆä»½è®Šå‹•ï¼Œé”æˆã€Œä¸€å€‹æœˆè‡ªå‹•æ¯”å°ä¸€æ¬¡ã€
    current_month = datetime.now().strftime("%Y-%m")
    try:
        file_id = pdf_link.split('/')[-2] if '/file/d/' in pdf_link else pdf_link.split('id=')[-1]
        direct_url = f'https://drive.google.com/uc?export=download&id={file_id}'
        response = requests.get(direct_url, timeout=10)
        images = convert_from_bytes(response.content, dpi=100)
        
        found_dt = ""
        for img in images:
            text = pytesseract.image_to_string(img, lang='chi_tra')
            match = re.search(r"(\d{2,3}|20\d{2})[\s\.å¹´/-]*(\d{1,2})[\s\.æœˆ/-]*(\d{1,2})", text)
            if match:
                yy, mm, dd = match.groups()
                year = int(yy) + 1911 if int(yy) < 1000 else int(yy)
                found_dt = f"{year}-{mm.zfill(2)}-{dd.zfill(2)}"
                break
        
        s_clean = str(sheet_date)[:10].replace('-', '')
        p_clean = found_dt.replace('-', '')
        return (s_clean == p_clean), found_dt
    except:
        return True, "è·³éè¾¨è­˜" # è‹¥é€£çµå¤±æ•ˆä¸é¡¯ç¤ºç•°å¸¸ï¼Œç”±ä¸‹è¼‰æŒ‰éˆ•è™•ç†

# ... (å…¶é¤˜åˆå§‹åŒ–èˆ‡æ•¸æ“šè¼‰å…¥ load_all_data / load_logs ä¿æŒä¸è®Š) ...

try:
    main_df, file_df = load_all_data()
    today = pd.Timestamp(date.today())

    # --- ğŸ“‚ å´é‚Šé¸å–® ---
    # ... (å°èˆªæŒ‰éˆ•é‚è¼¯ä¸å‹•) ...

    # --- æ¸²æŸ“é‚è¼¯ ---
    if st.session_state.mode == "library":
        st.header("ğŸ“ è¨±å¯ä¸‹è¼‰å€")
        st.caption("ğŸ” ç³»çµ±æ¯æœˆè‡ªå‹•æ ¸å° PDF å…§å®¹èˆ‡è³‡æ–™åº«æ—¥æœŸæ˜¯å¦ä¸€è‡´")
        
        for idx, row in main_df.iterrows():
            c1, c2, c3, c4 = st.columns([2, 1, 1, 1])
            c1.write(f"ğŸ“„ **{row.iloc[2]}**")
            c2.write(f"ğŸ“… åˆ°æœŸ: {str(row.iloc[3])[:10]}")
            
            url = row.get("PDFé€£çµ", "")
            if pd.notna(url) and str(url).strip().startswith("http"):
                # é€™è£¡å°±æ˜¯èƒŒæ™¯è‡ªå‹•æ ¸å°ï¼Œä¸éœ€è¦æŒ‰éˆ•
                is_match, pdf_dt = ai_verify_background(str(url).strip(), row.iloc[3])
                
                c3.link_button("ğŸ“¥ ä¸‹è¼‰ PDF", str(url).strip(), use_container_width=True)
                
                if not is_match:
                    # å¦‚æœæ¯”å°ä¸ç¬¦ï¼Œåœ¨ç¬¬å››æ¬„å™´å‡ºç•°å¸¸è­¦å‘Š
                    c4.markdown(f"""<div style="color: #d32f2f; font-weight: bold; padding: 5px; border: 1px solid #d32f2f; border-radius: 5px; text-align: center;">âš ï¸ æ¯”å°ç•°å¸¸<br><span style="font-size: 0.7rem;">PDFæ—¥æœŸ: {pdf_dt}</span></div>""", unsafe_allow_html=True)
                else:
                    c4.markdown('<p style="color: #2E7D32; text-align: center; margin-top: 10px;">âœ… å…§å®¹ä¸€è‡´</p>', unsafe_allow_html=True)
            else:
                c3.button("âŒ ç„¡é€£çµ", disabled=True, use_container_width=True)
            st.divider()

    elif st.session_state.mode == "cases":
        display_penalty_cases()
            
    else:
        # --- ğŸ“‹ è¨±å¯è­‰è¾¦ç†ç³»çµ± (ä¿æŒä½ åŸæœ¬çš„æ‰€æœ‰åŠŸèƒ½) ---
        # ... (é€™éƒ¨åˆ†åŒ…å«ä½ è¦æ±‚ä¿ç•™çš„ 180å¤©å»ºè­°ã€ç®¡åˆ¶ç·¨è™Ÿã€é™„ä»¶ä¸Šå‚³ç­‰ï¼Œä»£ç¢¼å®Œå…¨ä¸å‹•) ...
        # (é€™è£¡çœç•¥é‡è¤‡çš„è¾¦ç†é‚è¼¯ï¼Œè«‹æ²¿ç”¨ä¸Šä¸€ç‰ˆçš„å…§å®¹)

except Exception as e:
    st.error(f"âŒ ç³»çµ±éŒ¯èª¤ï¼š{e}")
